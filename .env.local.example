# Copiez ce fichier en .env.local et remplissez les valeurs.
# .env.local n'est pas commité (sécurité).

# === Analyse de toxicité (Hugging Face) ===
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# HF_INFERENCE_URL=   # optionnel

# === Analyse de sentiments (Hugging Face) ===
# Modèle : nlptown/bert-base-multilingual-uncased-sentiment
# HF_SENTIMENT_URL=   # optionnel (défaut: https://router.huggingface.co/models/nlptown/bert-base-multilingual-uncased-sentiment)
# HF_SENTIMENT_SCRIPT=scripts/hf_sentiment.py

# === Génération d'images : Hugging Face (text-to-image) ===
# Si HF_TOKEN est renseigné, il est utilisé en priorité pour la génération d'images.
# Le token doit avoir la permission "Inference Providers" (voir guide docs/HF_IMAGE_ETAPES.md).
# Modèle par défaut : ByteDance/SDXL-Lightning (Replicate).
# HF_IMAGE_MODEL=ByteDance/SDXL-Lightning
# HF_IMAGE_BASE_URL=   # optionnel (défaut: https://router.huggingface.co)
# Si erreur 410/404 : pip install huggingface_hub et décommenter :
# HF_IMAGE_SCRIPT=scripts/hf_image.py
# HF_IMAGE_PROVIDER=replicate   # optionnel

# === Génération d'images (Vertex AI Imagen) ===
# Projet Google Cloud (ex: image)
VERTEX_AI_PROJECT_ID=votre-project-id
# Région (ex: us-central1)
VERTEX_AI_LOCATION=us-central1
# Clé API créée dans Google Cloud > Identifiants, restreindre à "Vertex AI API"
VERTEX_AI_API_KEY=votre-cle-api

## (Chat psy / Dialogflow désactivé – aucune configuration nécessaire)
